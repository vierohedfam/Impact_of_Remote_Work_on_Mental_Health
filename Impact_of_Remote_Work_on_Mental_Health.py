# -*- coding: utf-8 -*-
"""Tugas 1 data Viero.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vV29wh7xtIRmmBSFNndRKQ4b8yoXBpY6
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

data=pd.read_csv('/content/Impact_of_Remote_Work_on_Mental_Health.csv')
data

data.isnull().sum()

# memeriksa data
data.isnull().sum()
for x in data.columns:
  print(data[x].value_counts())

data.isnull().sum()

data.interpolate()
data

# membuang yang tidak penting
data=data.dropna()
data=data.drop("Employee_ID", axis=1)
data=data.drop("Mental_Health_Condition", axis=1)
data=data.drop("Physical_Activity", axis=1)
data

wl = {"Hybrid":1, "Remote":2, "Onsite":3}
sl = {"Low":1, "Medium":2, "High":3}
sq = {"Poor":0, "Avarage":1, "Good":2}
gdr = {"Male":1, "Female":2, "Non-binary":3}
jr = {"HR":1, "Data Scientist":2,"Software Engineer":3, "Sales":4}
i = {"Healthcare":1," IT": 2, "Education":3, "Finance":4, "Consulting":5}
mhr = {"No":1, "Yes":2}
pc = {"Decrease":1, "Increase":2, "No Change":3}
swrw = {"Unsatisfied":1, "Satisfied":2, "Neutral":3}
r = {"Europe":1, "Asia":2, "North America":3, "Africa":4, "Oceania":5}
data["Work_Location"] = data["Work_Location"].replace(wl)
data['Stress_Level'] = data['Stress_Level'].replace(sl)
data['Sleep_Quality'] = data['Sleep_Quality'].replace(sq)
data['Gender'] = data['Gender'].replace(gdr)
data['Job_Role'] = data['Job_Role'].replace(jr)
data['Industry'] = data['Industry'].replace(i)
data['Access_to_Mental_Health_Resources'] = data['Access_to_Mental_Health_Resources'].replace(mhr)
data['Productivity_Change'] = data['Productivity_Change'].replace(pc)
data['Satisfaction_with_Remote_Work'] = data['Satisfaction_with_Remote_Work'].replace(swrw)
data['Region'] = data['Region'].replace(r)
data_one_hot_encoded = pd.get_dummies(data, columns=[
    'Work_Location', 'Stress_Level', 'Sleep_Quality', 'Gender',
    'Job_Role', 'Industry', 'Access_to_Mental_Health_Resources',
    'Productivity_Change', 'Satisfaction_with_Remote_Work', 'Region'
])
data_one_hot_encoded

# Memfilter hanya kolom numerik
numerical_data = data.select_dtypes(include=['float64', 'int64'])

# Membuat heatmap korelasi
plt.figure(figsize=(10, 8))
sns.heatmap(numerical_data.corr(), annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Heatmap Korelasi Data Numerik')
plt.show()

# mencari outlier
sns.boxplot(data["Number_of_Virtual_Meetings"])

# menghitung kuartil dan IQR
desc = data.describe()
q1 = desc.loc["25%"]
q3 = desc.loc["75%"]
iqr = q3 - q1

# menghitung batas bawah dan atas untuk mendeteksi outliers
lower = q1 - 1.5 * iqr
upper = q3 + 1.5 * iqr

# menghilangkan outliers di setiap kolom numerik
for col in data.select_dtypes(include='number').columns:
  data = data[(data[col] > lower[col]) & (data[col] < upper[col])]

# menampilkan data yang sudah dibersihkan dari outliers
data

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(data_one_hot_encoded)
scaled_data_df = pd.DataFrame(scaled_data, columns=data_one_hot_encoded.columns)
scaled_data_df